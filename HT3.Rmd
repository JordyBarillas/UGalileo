---
title: "Hoja de trabajo 3"
output: html_notebook
---

```{r}
#Librerias
library(dplyr)
library(ggplot2)
library(MASS) #para sacar el boxcox
library(corrplot) #correlaciones
library(glmnet) #regularizaciones
library(caret) 
```

### 1. Carga y exploración de datos.

#### 1.1. Importa los datos en R.
```{r}
nombre <- 'auto-mpg.csv'
(df <- read.csv(nombre))
```
#### 1.2. Examina la estructura de los datos (str(df)).
```{r}
(str(df))
```
#### 1.3. Calcula estadísticas descriptivas de las variables mpg , weight y horsepower.
```{r}
est_desc <- df[c("mpg", "weight", "horsepower")]
summary(est_desc)
```
### 2. Regresión lineal simple

#### 2.1. Ajusta un modelo de regresión lineal simple con mpg como variable dependiente y weight como variable independiente.
```{r}
modelo1 <- lm(mpg ~ weight, data=df)
summary(modelo1)
```
#### 2.2. Interpreta los coeficientes del modelo. ¿Cuál es el efecto estimado del peso sobre el consumo de combustible? ¿Es estadísticamente significativo?
```{r}
# El modelo muestra un intercepto con el valor de 46.3173644 cuando X sea igual a 0. Por otro lado, por cada unidad sumado al peso (dependiente), la variable mpg (independiente) disminuye -0.0076766, lo que quiere decir una relación inversamente entre las variables.
# La relación entre las variables es estadísticamente significativa.
```

#### 2.3. Evalúa la bondad de ajuste del modelo (R cuadrado).
```{r}
# Vemos un R cuadrado de 0.6918 lo que significa que el 69% de la variación en Y se explica por el modelo.
```

#### 2.4. Realiza un diagnóstico del modelo:
- Crea gráficos de residuos (residuos vs. valores ajustados, residuos vs. weight, histograma de residuos, gráfico Q-Q).
```{r}
# Residuos vs valores ajustados
residuos <- residuals(modelo1)
valores_ajustados <- fitted(modelo1)
plot(residuos, valores_ajustados)
```
```{r}
# Residuos vs. weight
plot(residuos, df$weight)
```
```{r}
#Histograma de residuos
hist(residuos)
```
```{r}
# Grafico Q-Q
qqnorm(residuos)
qqline(residuos)
```
- ¿Observas algún problema en los supuestos del modelo (linealidad, homocedasticidad, normalidad)?
```{r}
# -La grafica de residuos vs. variable independiente, se observa que estan dispersos alrededor de cero. Sin embargo, la grafica de residuos vs valores ajustados muestra un patron de embudo lo que puede sugerir un problema de heterocedasticidad o no linealidad (varianza no constante entre los errores).
# -El histograma de residuos sugiere una normalidad debido a que siguen una distribucion aproximadamente normal. Sin embargo, la grafica Q-Q se puede observar que al final de la cola los puntos se desvian de la linea recta, lo que sugiere una no normalidad de los errores.
```

- Si es necesario, aplica transformaciones a la variables (por ejemplo, logaritmo, inversa, etc) para corregir los problemas y vuelve a ajustar el modelo.

```{r}
#Histograma con la distribucion normal de la variable mpg
ggplot(df, aes(x=mpg)) +
  geom_histogram()
```


```{r}
#Transformacion logaritmica:
logaritmica = data.frame(log = log(df$mpg), price = df$mpg)
```

```{r}
ggplot(logaritmica, aes(x=log)) +
  geom_histogram()
```
```{r}
#Transformacion Raiz cuadrada
raiz_cuadrada <- data.frame(mpg = df$mpg, raiz = sqrt(df$mpg))

ggplot(data = raiz_cuadrada) +
  aes(x = raiz_cuadrada$raiz) +
  geom_histogram()
```
```{r}
#Transformacion Polinomica
polinomica <- data.frame(mpg = df$mpg, poli = df$mpg^2)

ggplot(data = polinomica) +
  aes(x = poli) +
  geom_histogram()
```
```{r}
#Transformacion Inversa
inversa <- data.frame(mpg = df$mpg, inv = 1 / df$mpg)

ggplot(data = inversa) +
  aes(x = inv) +
  geom_histogram()
```
```{r}
#Transformacion Box-Cox
bc <- boxcox(mpg ~ weight, data = df)
(lambda <- bc$x[which.max(bc$y)])
```
```{r}
#Almacenamos la columna transformada en el dataset
(df <- df %>% 
  mutate(mpg_bc = ((df$mpg^lambda - 1) / lambda)))
```
```{r}
#Creacion del nuevo modelo ajustado
modelo2 <- lm(mpg_bc ~ weight, data = df)
summary(modelo2)
```
```{r}
#Graficamos los residuos, y vemos que la grafica de residuos vs. valores ajustados ya no tiene un patron de embudo. Además la grafica Q-Q tiene los puntos mas pegados a la linea diagonal
plot(modelo2)
```
### 3. Regresión lineal múltiple

#### 3.1. Ajusta un modelo de regresión lineal múltiple con mpg como variable dependiente y weight, horsepower y acceleration como variables independientes.
```{r}
#Transformacion de variable categorica horsepower.
df$horsepower <- factor(df$horsepower)
levels(df$horsepower)

#Creacion del modelo
modelo3 <- lm(mpg ~ weight + horsepower + acceleration, data = df)
summary(modelo3)
```

#### 3.2. Interpreta los coeficientes del modelo. ¿Cuál es el efecto estimado de cada variable independiente sobre el consumo de combustible, manteniendo constantes las demás variables?

```{r}
# El modelo muestra un intercepto con el valor de 4.143e+01 cuando X sea igual a 0. Por otro lado, por cada unidad sumado a la variable weight y acceleration, la variable mpg disminuye, lo que quiere decir una relación inversamente entre las variables. Esto también aplica principalmente para vehículos con 100 o más caballos de fuerza. 
# La relación con la variable weight es estadísticamente significativa, sin embargo, con las demas variables vemos principalmente que no es sginificativo.
```

#### 3.3. Evalúa la bondad de ajuste del modelo (R cuadrado).
```{r}
# Vemos un R cuadrado de 0.8281 lo que significa que el 82.81% de la variación en Y se explica por el modelo. Adicional vemos un R cuadrado ajustado bueno por 0.7741, útil para evaluar un modelo con múltiples variables.
```

#### 3.4. Realiza un diagnóstico del modelo:
- Crea gráficos de residuos.
```{r}
plot(modelo3)
```
-Evalua si puedes detectar multicolinealidad. Puedes utilizar lo visto en clase o investigar sobre VIF (inflación de la varianza)
```{r}
temp <- df[c('weight','acceleration')]
temp
```
```{r}
#Primera evaluacion sobre las variables weight y acceleration.
matrix <- cor(temp)
corrplot(matrix, method='number')

#Como resultado vemos que la correlacion entre las variables es baja, por lo que no hay multicolinealidad entre estas dos variables.
```
```{r}
#Primero ajustamos el nuevo modelo eliminando la variable horsepower. No sera necesario usar regularizaciones dado que no existe multicolinealidad entre variables independientes.
modelo4 <- lm(mpg ~ weight + acceleration, data = df)
summary(modelo4)
```

```{r}
#Probaremos el siguiente modelo con la transformacion box cox sobre la variable mpg.
modelo5 <- lm(mpg_bc ~ weight + acceleration, data = df)
summary(modelo5)
```
###### Vemos que mejora la significancia de las variables independientes y el R cuadrado, por lo que el modelo anterior es mas optimo.

### 4. Variables dummy

#### 4.1. Convierte la variable categórica origin en variables dummy.
```{r}
df$origin <- factor(df$origin)
levels(df$origin)
```

#### 4.2. Ajusta un nuevo modelo de regresión múltiple incluyendo las variables dummy de origin junto con las variables continuas (weight, horsepower, acceleration).
```{r}
modelo6 <- lm(mpg ~ weight + origin + horsepower + acceleration, data = df)
summary(modelo6)
```
#### 4.3. Interpreta los coeficientes de las variables dummy. ¿Cuál es el efecto estimado de cada origen en el consumo de combustible, en comparación con la categoría de referencia?
```{r}
# Vemos que entre las variables dummy, la de Origin2 no es significativa para el modelo, mientras que la la variable Origin3 si es significativa.
# Vemos un R cuadrado de 0.8405 lo que significa que el 84.05% de la variación en Y se explica por el modelo. Adicional vemos un R cuadrado ajustado bueno por 0.7889, útil para evaluar un modelo con múltiples variables.
```

#### 4.4. Realiza un diagnóstico del modelo para verificar si la inclusión de las variables dummy ha mejorado el ajuste o ha introducido nuevos problemas.

```{r}
## Al observar la significancia de las variables y el R cuadrado, vemos como mejora el ajuste del modelo en comparación con el modelo 3. Sin embargo hay que considerar que horsepower sigue aportando variables que no son significativas.  
```

### 5. Modelo libre

- Realiza un modelo múltiple con cualquier combinación de las variables disponibles.

```{r}
(df_numericas <- df[c('mpg', 'cylinders', 'weight', 'model.year', 'displacement', 'acceleration')])
```
```{r}
#Evaluacion de otras variables disponibles
(matriz <- cor(df_numericas))
corrplot(matriz, method='number')
```
```{r}
#Selección de modelo con base a la correlacion entre las variables independientes y la dependiente transformada.Ademas, vemos que no existe una multicolinealidad entre las variables seleccionadas.
modelo7 <- lm(mpg_bc ~ weight + model.year + origin, data = df)
summary(modelo7)
```
```{r}
#Analisis de residuos del modelo anterior
plot(modelo7)
#En la grafica de residuos vs fitted no vemos un patron, y en la grafica Q-Q vemos como los valores se pegan a la linea diagonal.
```

